>> Classical machine learning can take you so far, but all the cool kids are getting into so-called deep learning. So let's take a look at that. As you know, machine learning is fundamentally about defining a function that produces a label value, y, from a set of features, x. Now the features are usually numeric values, like the measurements of an iris flower's petals and sepals, and in classification, the label is a probability vector that identifies the most likely class to which the item described by the features belongs. Classical machine learning techniques use algorithms like logistic regression, to determine coefficients for the function. We're going to look at a different approach that tries to mimic the human brain. In your brain, you have neurons, and attached to these neurons are nerve tissues called dendrites that contain synapses that capture input signals for the neuron. As you learn to respond to specific stimuli, these nerve impulses are strengthened or weakened. If the input signal is strong enough, the neuron fires, passing the signal onto other neurons in the neural network that forms your central nervous system. Then conceptually, you can think of this biological arrangement is being like a mathematical function. The impulses received by the neurons are input values which we'll call x. In this case there's a vector of 2x values that we'll call x1 and x2. Whether or not the neuron fires, is our output value or y. We can also view the strength or weakness of the input signal as being something that's used to assign weight to each input value, so we will call this w. All of that gives us a function that operates on x and w to produce y. Because this is an artificial neuron, we want to have some additional control over whether or not the neuron fires. So we actually add an additional input that we call bias or b. So our function now operates on x, w, and b, to produce y. But what does it actually do? Well, at the core, it calculates a weighted sum of each x input multiplied by its corresponding weight, and adds the bias value. This can produce theoretically any numerical value for y. We want to simulate a neuron which fires or doesn't, depending on whether or not a specific threshold is reached. So we wrap the weighted sum in a function that squashes the output value within a specific range, often a sigmoid function that yields a value between between zero and one. We call this function and activation function, and it's what determines whether or not our artificial neuron fires. So how does this artificial neuron function work in a machine learning model? Well, let's take some input values, in this case a vector containing the sepal and petal, width and height measurements for an iris, and we'll create a neuron for each input. So we're passing 1x value, with a randomly generated weight and bias value into each neuron. We're calculating a weighted sum, and we're using an activation function to squeeze the result between zero and one. Then the neurons in this input layer pass their outputs onto another layer of neurons, with each neuron in the first layer being connected to every neuron in the second layer. Again, the weights and bias values are randomly initialized. We can have as many of these layers as we like, we call them hidden layers, until finally we connect the outputs to an output layer, that has the same number of neurons as we have classes to which we are trying to assign the observed features. In this case, three classes representing the three possible species of virus. The output from the final output layer contains a probability value for each class, which we can interpret as a vector. Now this whole network of fully-connected layers is called a neural network or sometimes a multilayer perceptron. Now, the clever bit is that because we're training this network with some iris data where we already know the correct classes, we can compare the probability values that are generated by the network to the actual known values. In this case, the features in the input layer are measurements of a Virginica iris, which is the second of our three classes. So the correct probability should be zero, one, and zero. Now we can measure how far off each of our predicted probabilities are from the actual grown truth label. Then we'll take the mean of that, and we'll square it. That gives us a metric that indicates the amount of error in the model, which we call as loss. So now that we know how to calculate the loss in the model, what can we do with it? Well, the calculation for the loss is a function which takes as input the output layer of the neural network, which in turn can be thought of as a function that operates on its weights and biases that it gets from the output of the layer before, and so on, all the way back to the original input layers, values, weights, and biases. In effect, the neural network and its lost function just form one big nested function. Like any function, we can plot its output for any combination of its inputs. So to keep things simple, let's for a moment pretend that the lost function is only one input value, a weight value named w_1, and it produces an output which measures the loss in our network. Here's the point on the plot that shows the loss generated for w_1, value of two. Using differential calculus, we can calculate the derivative of the function at this point. In other words, we can figure out the direction of the slope or gradient of the function line when w_1 is two. In this case, the derivative is negative. So we know that if we increase the value of w_2, then the gradient of the function will go down reducing the loss. Now of course, our function is a little more complex. It has many input variables, but the same principle applies to a multivariate function. It's just that the plot becomes multidimensional, and we need to calculate a partial derivative for each input variable. This tells us which direction we need to adjust each variable in order to move the loss down, in effect descending the gradient of the function to reduce the loss. The amount we adjust each variable by is called the learning rate. A low value for the learning rate results in small adjustments. So we might need to adjust the variables many times to minimize the loss. A high learning rate results in large adjustments. So we might step too far, and not find the minimum part of the gradient. In practice, setting the learning rate require some trial and error, and you can use advanced techniques to change the learning rate as we get closer to minimizing the loss. We can calculate derivatives for any of the variables in the functions. Thanks to a feature of calculus called the chain rule, we can work recursively back through any number of nested functions to calculate derivatives for every variable that affects the final outcome, in this case the loss. So if we apply this to our neural network, we can work backwards to determine how best to adjust every weight and bias value in the network in order to reduce the amount of loss in the model, we call this backpropagation. With the weights and biases adjusted, when we feed the same input values into the network, we get a different output which should hopefully result in a lower loss. Which means our network is improving, it's learning. To train our network, we just feed through a bunch of feature vectors for which we already know the class labels. Then our loss function calculates the loss averaged for all of the training data, and we backpropagate, to adjust the weights and bias values based on our chosen learning rate. Then we can feed through some more feature vectors with known labels to validate the new weights and biases. Each cycle of training backpropagation and validation is called an epoch, and we go through several of these to train the model. Within each epoch, we don't feed the feature vectors through one at a time. We actually combine them into multiple batches. So actually, we're processing a matrix of feature values. The weights and biases are vectors. So this process is actually just some linear algebra calculations. Now that kind of math is heavily used in computer graphics. Graphical processing units or GPUs are optimized for this type of operation. That's why when we're training deep learning models, we tend to use computers with GPUs. It's generally much faster than using just CPUs.