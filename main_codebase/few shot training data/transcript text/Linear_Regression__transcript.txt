our first learning algorithm will be linear regression in this video you see what the model looks like and more importantly you also see what the overall process of supervised learning you'll flip let's use a motivating example of predicting housing prices we're going to use a data set of housing prices from the city of Portland Oregon and you're going to plot my data set of a number of houses there were different sizes that were so for a range of different prices let's say that given this data set you have a friend that's trying to sell a house and let's see your friend's house is of size 1,250 square feet and you want to tell them how much they might be able to sell the house for well one thing you could do is fit to a model maybe put a straight line to this data then write something like that and based on that maybe you could tell your friend that looks likely to maybe sell the whole square around to $18,000 so this is an example of a supervised learning algorithm and it's supervised learning because we're given the quote right answer for each of our examples namely were told what was the actual house what was the actual price that each of the houses in our data set was so for and moreover does an example of a regression problem where the term regression refers to the fact that we're predicting a real-valued output maybe the price and then just remind you the other type the other most common type of supervised learning problem is called the classification problem where we predict discrete values outputs such as if we are looking at cancer tumors and trying to decide if a tumor is malignant or benign so there's a 0 1 value distrito more formally in supervised learning we have a data set and this data set is called a training set so for a housing price an example we have a training set of different housing prices and our job is to learn from this data how to predict the prices of the houses let's define some notation that we're using throughout this course I'm going to define quite a lot of symbols is okay if you don't remember all the symbols right now but as the course progresses so be useful with a convenient notation so I'm going to use lowercase M throughout this course to denote the number of training examples so in this data set if I have you know let's say 47 rows in this table then I have 47 training examples and M equals 47 let me use lowercase X to denote the input variables often also called the features so though the X's here will be on input features and I'm going to use Y to denote my output variables or the target variable region to predict its Alexis second column here a little bit more notation I'm going to use X comma Y to denote a single training example so a single row in this table corresponds to a single training example and to refer to a specific training example I'm going to use this notation X I comma Y I and going to use this to refer to the training example so this superscript I over here this is not exponentiation right this X I Y I the superscript I in parenthesis that's just an index into my training set and it refers to the I row in this table okay so this is not except our of iy ^ I instead X I Y I just refers to the I fro of this table so for example X 1 you know refers to the input value for the first training example so that's 21 0 4 represents X to the first row X 2 would be equal to 14 16 right the second x and y 1 will be equal to 460 with that's the first the Y value for my first training example that's what that one refers to so as I mentioned occasionally I'll ask you a question to let you check your own understanding and a few seconds in this video a multiple-choice question will pop up in the video when it does please use your mouse to select what you think is the right answer we're defined by the training set is and so here's how a supervised learning works we solve them of a training set like our training set of housing prices and we feed that to our learning algorithm is the job of a learning algorithm to then output a function which by convention is usually denoted lowercase H and H stands for hypothesis and what the job of the hypothesis is is is a function that takes as input the size of a house like maybe the size of a new house that your friend is trying to sell it takes in a value of X and it tries to output the estimated value of y for their corresponding house so H is a function that map's from X's to YS um people often ask me you know why is this function called a hypothesis some of you may know the meaning of the term hypothesis from the dictionary or from signs or whatever it turns out that the machine learning this is a name that was used in the early days of machine learning and this kind of stuff because maybe not a great name for this sort of function for mapping from sizes of houses to the predictions but you know I think the term hypothesis maybe isn't the best possible name for this but is what this is the standard terminology that people using here you know so don't worry do it don't worry too much about why people call it that when designing a learning algorithm the next thing we need to decide is how do we represent this hypothesis H for this in the next few videos I'm going to choose our initial choice for representing the hypothesis will be the following going to represent H as follows and with the right of this subscript theta of x equals theta 0 plus theta 1 of X and as a shorthand sometimes instead of writing you know H subscript theta of X sometimes it's a shorthand I'll just write this is H of X but more often our rector the subscript theta over there and plotting to some pictures all this means is that we are going to you know predict that Y is a linear function of X right so there's a data set and what this function is doing is just predicting that Y is some straight line function of X s of x equals 3 0 plus theta 1 X ok and why a linear function well sometimes we'll want to fit more complicated perhaps nonlinear functions as well but since this linear case is the simple building block we'll start with this example first so fitting linear functions and we'll build on this to eventually have more complex models in more complex learning algorithms let me also give this particular model a name small though is called linear regression or district example is a actually linear regression with one variable will be variable being X some connecting housing prices functions in one variable X and another name for this model is you need the area linear regression and you need area is just you know a fancy way of saying one variable so that's linear regression in the next video we'll start to talk about just how to go about implementing this model